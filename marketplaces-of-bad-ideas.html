<!doctype html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport"
          content="width=device-width, user-scalable=no, initial-scale=1.0, maximum-scale=1.0, minimum-scale=1.0">
    <meta name="viewport"
          content="width=device-width, user-scalable=yes, initial-scale=1.0, maximum-scale=3.0, minimum-scale=1.0">
    <meta http-equiv="Content-Language" content="en">
    <meta http-equiv="X-UA-Compatible" content="ie=edge">

    <title>Marketplaces of Bad Ideas</title>
    <meta name="description" content="Letters to myself."/>
    <meta name="keywords" content="blog,programming,philosophy,game development"/>

    <link rel="stylesheet"
          href="https://fonts.googleapis.com/css?family=Alegreya:400,400i|Lato:400,400i,700,900|Roboto+Mono:400,300">
    <link rel="stylesheet"
          href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.5.1/styles/shades-of-purple.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.5.1/highlight.min.js"></script>

    <link rel="stylesheet" href="/css/normalize.css"/>
    <link rel="stylesheet" href="/css/theme.css"/>
</head>
<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-N01RTZNKXF"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-N01RTZNKXF');
</script>

<body>
<nav class="nav">
    <div class="nav__left">
        <a href="/">Home</a>
        <a href="/about">About</a>
    </div>
    <div class="nav__right">
        <a target="_blank" href="https://github.com/cowtrix" class="link-github">GitHub</a>
        <a href="mailto:seandgfinnegan@gmail.com" class="link-email">Email</a>
    </div>
</nav>

<article class="mar-b-7">
    <header class="text-center">
        <time class="mar-b-6" datetime="Wed, February 24, 2021">Wed, February 24, 2021</time>
        <h1 class="mar-b-7">Marketplaces of Bad Ideas</h1>
        <span class="post-tags">Tags: Reflection, Philosophy</span>
    </header>
    <p>You might have heard of "The Marketplace of Ideas" (hereafter referred to as a MoI). This phrase is means a certain freedom to discuss, promote and pursue <em>any</em> ideology within a "free" or otherwise unregulated landscape. If we take it at face value, the MoI promises that if you just let ideas fight it out on some level-playing-field, the <strong>good</strong> ones will rise at the top.</p>
<p><img src="https://media1.giphy.com/media/Yqhr57aohKbKH2emhK/giphy.gif?cid=ecf05e47dl6uxgwbg759twtbfw6013g6c50113d3i773k411&rid=giphy.gif" alt="Normative Statement Alert" /></p>
<p><em>WARNING WARNING <a href="https://en.wikipedia.org/wiki/Normative_statement">NORMATIVE STATEMENT DETECTED</a>. UNDEFINED HEURISTIC: "GOOD"</em></p>
<p>Oh boy! It's my old friend "A Normative Statement With An Unclear Heuristic". Big warning sign that we're straying out of objective territory, and that the tools of epistomology are about to fail us. The MoI promises to elevate the best ideas to the top - but what does it <em>mean</em> for an idea to be good here?</p>
<p>Well, the mechanism of the market gives us a circular answer - an idea is good if it is valued highly within the marketplace. If we go down this road, the purpose of the MoI is to select the good ideas, but the hueristic used to define that is also generated by the market. These kind of self-defining heuristics are an interesting and useful feature of markets in that they can naturally evolve as goals change. This is great for a lot of economics which concerns itself entirely with efficiency and empirically answerable questions like "what is the best way to feed everyone?". But in which markets exactly is it useful and safe to apply these circular heuristics?</p>
<ul>
<li>When the heuristic is empirically answerable: <em>How valuable is an apple?</em></li>
<li>When the magnitude of heuristic drift is small: <em>There aren't enough apples, or there are too many.</em></li>
<li>When there is a clear feedback loop between the heuristic and how that heuristic changes over time: <em>When there are lots of apples the price is cheap and vice versa.</em></li>
<li>When the optimization of the heuristic has no bad side effects: <em>More efficiently produced apples are good for everyone.</em></li>
</ul>
<p>But is that true for the commodity of ideology? I'm unconvinced. We seem to fail right off the bat with an empirical heuristic. Whether or not an idea is valuable likely depends on the potential utility. You are far more likely to support an ideology wherein you are powerful and oppose ideologies where you are powerless. That is certainly true to an extent within many markets, but combined with the lack of any real pricing mechanism, we are lost in a sea of incomparability.</p>
<p>We do no better with judging the magnitude of heuristic drift. Without being able to define an empirical heuristic, how do we objectively judge how we have drifted from it? I can make a subjective judgement that I prefer our current world of discourse over some fuedalistic past, but it is just subjective and not an assumption that I can assume the market will understand and enforce.</p>
<p>What of this feedback loop? Certainly one exists. Human history is one of evolving struggle, conflicting forces resolving into some new conflicting force and then again in a seemingly endless cycle of expansion and turmoil that constantly feeds back on itself. But if there is some clear thread between past ideologies and the future, I do not see it. Our breadth of ideology, in both commitment and strangeness, seems to know no bounds. Considering the absence of any real accurate predictions from even a few years ago, it seems unlikely that we will ever understand this feedback loop enough to master it.</p>
<p>Finally, what does it mean for this heurisitic to be optimized? Within a consumer market, agent optimization means maximization of market share and consumption. Within a MoI, it seems that optimization maximizes much the same - the ideas that spread the most, and sit most deeply within people's minds, are the ideas which will dominate. What does it mean for this market that it will optimise for the transmissibility of an idea, and not the correctness of it? We would do well to remember that the convincingness of an idea does not necessarily corellate with its correctness. The universe is under no obligation to convince you, whereas your mind tries very hard to do so constantly.</p>
<p>You might protest: surely, a market is a democratic mechanism? A market of ideas, merely the democratic process in action as arguers and arguees engage in an ongoing act of ideological natural selection? But I think about how people do not engage directly with any market. They do so through some proxy of power. People engage with economic markets through the power-proxies of wealth and capital. People engage with memetic markets through the power-proxies of media influence, cultural and social context, state propaganda, and (ever so rarely) considered discussion. A laissez-faire MoI allocates influence in proportion to this power, not in proportion to how "good" your ideas are within some arbitrary structure.</p>
<p>The issue is not memetic markets in general, but a completely laissez-faire ideological market that does not correct for a set of values. That MoI will prioritize the transmissibility of an idea over its utility. We might play around with the structure of the market to try and adjust these incentives towards ones we believe in - for instance, elevating ideas which seek to maximize agency and minimize suffering - but we should understand the arbitrary nature of this configuration. A MoI will not naturally produce these ideas, and must be shaped - as all markets must - by the irrationality of ethics. MoIs must be fine-tuned to generate ideas that you believe to be ethical. We can do so much around markets of ideas, markets of predictions, markets of visions for the future - but they cannot determine some consensus around foundational ethical values, and we can't pretend like they can. Doing so merely obfuscates that arbitrary landscape. A MoI that is configured in a way you disagree with will select highly optimal solutions that you may find deeply problematic or evil. The consequences of a highly sophisticated yet completely untuned MoI is one of very transmissibile and optimal - yet ethically bad - ideas rising to the top.</p>
</article>

<footer class="text-center mar-tb-6">
    Â© 2025 Sean Finnegan, unless otherwise stated.
</footer>

<script>hljs.highlightAll();</script>
</body>
</html>

